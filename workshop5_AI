{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMaWt3tdF7vgkV62vthW82/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"ASBPBRSOdlJ9","executionInfo":{"status":"error","timestamp":1766331048563,"user_tz":-345,"elapsed":81,"user":{"displayName":"Santosh Dahal","userId":"16163861815763051910"}},"outputId":"b7dd3059-a2c6-4c56-a1ab-c8c421c1061c"},"outputs":[{"output_type":"stream","name":"stdout","text":["---------- To Do 1: Data Analysis and Feature/Label Split ----------\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'student.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1199853270.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ---------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------- To Do 1: Data Analysis and Feature/Label Split ----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"student.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n1. Top 5 rows (data.head()):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Read and print top 5 rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'student.csv'"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","# Set random state for reproducibility (as suggested by best practice and implied in worksheet snippet)\n","np.random.seed(42)\n","\n","# ======================================================================\n","# Step 1: Data Understanding, Analysis and Preparations (To Do 1 & 2)\n","# ======================================================================\n","\n","# ---------------------------------\n","# To Do - 1: Data Reading and Observation\n","# ---------------------------------\n","print(\"---------- To Do 1: Data Analysis and Feature/Label Split ----------\")\n","data = pd.read_csv(\"student.csv\")\n","print(\"\\n1. Top 5 rows (data.head()):\")\n","print(data.head()) # Read and print top 5 rows\n","\n","print(\"\\n2. Bottom 5 rows (data.tail()):\")\n","print(data.tail()) # Print bottom 5 rows\n","\n","print(\"\\n3. Data Information (data.info()):\")\n","data.info() # Print information\n","\n","print(\"\\n4. Descriptive Statistics (data.describe()):\")\n","print(data.describe()) # Gather descriptive info\n","\n","# ---------------------------------\n","# To Do - 1 (Cont.) & To Do - 2: Split Features and Target (No Bias)\n","# ---------------------------------\n","\n","# Features: 'Math' and 'Reading' (X)\n","# Label/Target: 'Writing' (Y)\n","# The model assumes no bias/intercept, so no column of 1s is added (To Do 2 Note 3)\n","X = data[['Math', 'Reading']].values\n","Y = data['Writing'].values.reshape(-1, 1) # Reshape Y to (m, 1) matrix for vector operations\n","\n","# X: Feature Matrix (m x d, m=1000, d=2)\n","# Y: Target Vector (m x 1, m=1000)\n","print(f\"\\n5. Feature Matrix X shape: {X.shape}\")\n","print(f\"   Target Vector Y shape: {Y.shape}\")\n","\n","# ---------------------------------\n","# To Do - 3: Split Dataset\n","# ---------------------------------\n","print(\"\\n---------- To Do 3: Dataset Split (80/20) ----------\")\n","# Split the data into 80% training and 20% testing sets\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","print(f\"Training set size (X_train): {X_train.shape[0]} samples\")\n","print(f\"Test set size (X_test): {X_test.shape[0]} samples\")\n","\n","\n","# ======================================================================\n","# Step 2: Build a Cost Function (To Do 4 & 5)\n","# ======================================================================\n","\n","# ---------------------------------\n","# To Do - 4: Implement Cost Function (Mean Squared Error)\n","# ---------------------------------\n","def cost_function(X, Y, W):\n","    \"\"\"\n","    Finds the Mean Square Error (MSE) cost.\n","    L(w) = (1/2n) * sum((Y_pred - Y)^2)\n","\n","    Input parameters:\n","    X: Feature Matrix (m x d)\n","    Y: Target Matrix (m x 1)\n","    W: Weight Matrix (d x 1)\n","    \"\"\"\n","    m = len(Y)\n","    Y_pred = np.dot(X, W) # Y_pred = X * W (m x 1)\n","    cost = (1 / (2 * m)) * np.sum(np.square(Y_pred - Y))\n","    return cost\n","\n","print(\"\\n---------- To Do 4: Cost Function Implementation (MSE) ----------\")\n","print(\"Cost function 'cost_function(X, Y, W)' defined.\")\n","\n","# ---------------------------------\n","# To Do - 5: Test Cost Function\n","# ---------------------------------\n","print(\"\\n---------- To Do 5: Test Case for Cost Function ----------\")\n","# Provided Test Case (Note: X_test is transposed to match conventional (m x d) matrix for np.dot)\n","# X=matrix(1, 3, 5; 2, 4, 6) in worksheet is R(2x3) (d x n). We use (n x d)\n","X_test_manual = np.array([[1, 2], [3, 4], [5, 6]]) # 3 samples (rows), 2 features (columns)\n","Y_test_manual = np.array([3, 7, 11]).reshape(-1, 1) # 3 samples (rows), 1 target\n","W_test_manual = np.array([1, 1]).reshape(-1, 1) # 2 features (rows), 1 weight\n","\n","# Expected prediction: Y_pred = X_test_manual @ W_test_manual = [[1*1 + 2*1], [3*1 + 4*1], [5*1 + 6*1]] = [3, 7, 11]\n","# Expected cost: (1 / (2*3)) * ((3-3)^2 + (7-7)^2 + (11-11)^2) = 0\n","cost_output = cost_function(X_test_manual, Y_test_manual, W_test_manual)\n","\n","if cost_output == 0:\n","    print(f\"Test Passed: Cost function output: {cost_output:.4f}. Proceed Further.\")\n","else:\n","    print(f\"Something went wrong: Reimplement a cost function. Output: {cost_output:.4f}\")\n","\n","# ======================================================================\n","# Step 3: Implement Gradient Descent (To Do 6 & 7)\n","# ======================================================================\n","\n","# ---------------------------------\n","# To Do - 6: Implement Gradient Descent\n","# ---------------------------------\n","def gradient_descent(X, Y, W, alpha, iterations):\n","    \"\"\"\n","    Performs gradient descent to optimize the parameters (W) of a linear regression model.\n","    W_new = W_old - alpha * (1/m) * sum((Y_pred - Y) * X)\n","\n","    Parameters:\n","    X (numpy.ndarray): Feature matrix (m x d).\n","    Y (numpy.ndarray): Target vector (m x 1).\n","    W (numpy.ndarray): Initial weight vector (d x 1).\n","    alpha (float): Learning rate.\n","    iterations (int): Number of iterations.\n","\n","    Returns:\n","    W: Optimized weight matrix (d x 1)\n","    cost_history: List of cost values over iterations\n","    \"\"\"\n","    m = len(Y)\n","    cost_history = []\n","\n","    for _ in range(iterations):\n","        # 1. Calculate the predicted values\n","        Y_pred = np.dot(X, W)\n","\n","        # 2. Compute the loss (error)\n","        loss = Y_pred - Y\n","\n","        # 3. Compute the gradients\n","        # (1/m) * X^T * (Y_pred - Y)\n","        # Gradient = (1/m) * sum(loss * X)\n","        gradients = (1 / m) * np.dot(X.T, loss)\n","\n","        # 4. Update the parameters (weights)\n","        W = W - alpha * gradients\n","\n","        # Calculate and record cost\n","        current_cost = cost_function(X, Y, W)\n","        cost_history.append(current_cost)\n","\n","    return W, cost_history\n","\n","print(\"\\n---------- To Do 6: Gradient Descent Implementation ----------\")\n","print(\"Gradient Descent function 'gradient_descent(X, Y, W, alpha, iterations)' defined.\")\n","\n","# ---------------------------------\n","# To Do - 7: Test Gradient Descent\n","# ---------------------------------\n","print(\"\\n---------- To Do 7: Test Case for Gradient Descent ----------\")\n","# Provided Test Case from the worksheet\n","m_test = 100\n","d_test = 3\n","np.random.seed(0) # For reproducibility\n","X_test = np.random.rand(m_test, d_test) # 100 samples, 3 features\n","Y_test = np.random.rand(m_test).reshape(-1, 1) # 100 targets\n","W_test = np.random.rand(d_test).reshape(-1, 1) # Initial guess for parameters\n","alpha = 0.01\n","iterations = 1000\n","\n","final_params, cost_history = gradient_descent(X_test, Y_test, W_test, alpha, iterations)\n","\n","print(\"Test Code for Gradient Descent function:\")\n","print(\"Final Parameters (First 3):\", final_params.flatten()[:3])\n","print(\"Initial Cost:\", cost_history[0])\n","print(\"Final Cost:\", cost_history[-1])\n","print(\"Cost History length:\", len(cost_history))\n","\n","\n","# ======================================================================\n","# Step 4: Model Evaluation Functions (To Do 8 & 9)\n","# ======================================================================\n","\n","# ---------------------------------\n","# To Do - 8: Implement RMSE\n","# ---------------------------------\n","def rmse(Y, Y_pred):\n","    \"\"\"\n","    Calculates the Root Mean Squared Error (RMSE).\n","    RMSE = sqrt((1/n) * sum((Y_pred - Y)^2))\n","    \"\"\"\n","    n = len(Y)\n","    mse = np.sum(np.square(Y_pred - Y)) / n\n","    return np.sqrt(mse)\n","\n","print(\"\\n---------- To Do 8: RMSE Implementation ----------\")\n","print(\"RMSE function 'rmse(Y, Y_pred)' defined.\")\n","\n","\n","# ---------------------------------\n","# To Do - 9: Implement R-Squared (R2)\n","# ---------------------------------\n","def r2(Y, Y_pred):\n","    \"\"\"\n","    Calculates the R-Squared Error.\n","    R2 = 1 - (SS_res / SS_tot)\n","    SS_res (Residual Sum of Squares) = sum((Y_pred - Y)^2)\n","    SS_tot (Total Sum of Squares) = sum((Y - mean(Y))^2)\n","    \"\"\"\n","    mean_y = np.mean(Y)\n","    ss_res = np.sum(np.square(Y - Y_pred)) # Residual Sum of Squares (SSR)\n","    ss_tot = np.sum(np.square(Y - mean_y)) # Total Sum of Squares (SST)\n","    rsquared = 1 - (ss_res / ss_tot)\n","    return rsquared\n","\n","print(\"\\n---------- To Do 9: R-Squared Implementation ----------\")\n","print(\"R-Squared function 'r2(Y, Y_pred)' defined.\")\n","\n","# ======================================================================\n","# Step 5: Main Function to Integrate All Steps (To Do 10 & 11)\n","# ======================================================================\n","\n","# ---------------------------------\n","# To Do - 10 & 11: Execute and Evaluate\n","# ---------------------------------\n","print(\"\\n---------- To Do 10 & 11: Execute Full Workflow and Evaluate ----------\")\n","\n","# 1. Initialize weights, learning rate, and iterations\n","# Since X_train has 2 features ('Math', 'Reading'), W must be (2 x 1)\n","W_initial = np.zeros((X_train.shape[1], 1))\n","alpha = 0.00001\n","iterations = 1000\n","\n","print(f\"Initial Weights (W): {W_initial.flatten()}\")\n","print(f\"Learning Rate (alpha): {alpha}\")\n","print(f\"Iterations: {iterations}\")\n","\n","# 2. Perform Gradient Descent (Training the Model)\n","W_optimal, cost_history = gradient_descent(X_train, Y_train, W_initial, alpha, iterations)\n","\n","# 3. Make predictions on the test set\n","Y_pred = np.dot(X_test, W_optimal)\n","\n","# 4. Evaluate the model using RMSE and R-Squared\n","model_rmse = rmse(Y_test, Y_pred)\n","model_r2 = r2(Y_test, Y_pred)\n","\n","# 5. Output the results\n","print(\"\\n--- Model Results ---\")\n","print(\"Final Weights (Optimal W):\")\n","# W_optimal[0] is the weight for 'Math' and W_optimal[1] is the weight for 'Reading'\n","print(f\"  Weight (Math):   {W_optimal[0][0]:.4f}\")\n","print(f\"  Weight (Reading): {W_optimal[1][0]:.4f}\")\n","\n","print(\"\\nPerformance Metrics on Test Set (20% of data):\")\n","print(f\"RMSE (Root Mean Squared Error): {model_rmse:.4f}\")\n","print(f\"R-Squared (R2) Score: {model_r2:.4f}\")\n","\n","print(\"\\nCost History:\")\n","print(f\"Initial Cost (MSE): {cost_history[0]:.4f}\")\n","print(f\"Final Cost (MSE):   {cost_history[-1]:.4f}\")\n","print(f\"Cost History (First 10 iterations): {cost_history[:10]}\")\n","print(f\"Cost History (Last 10 iterations): {cost_history[-10:]}\")"]}]}